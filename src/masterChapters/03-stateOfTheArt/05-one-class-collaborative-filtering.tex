% !TEX root = ../../report.tex
\section{One-Class Collaborative Filtering}

% todo - hva vil vi med denne sekjsonen?

\subsection{About}
    There are many applications where the feedback from a user is in binary form.
    Take for instance a item purchase page without explicit feedback.  The only
    feedback from a user might only be if an item has been purchased or not, the
    data consists only of binary data.  Other cases can include page visitation or
    webpage bookmarking.  The fallout of this is that the data collected from the
    user is usually really sparse.  And one issue which arises from the binary
    feedback is the lack of known negative feedback.  Does the fact that a user
    visited a web page, but not another indicate that the user dislikes the
    unvisited page, or simply that the user oversaw it?  The negative feedback and
    the missing feedback are mixed together in the bigger part of the dataset.
    Which makes it difficult to identify what is what.  Recommendations, through
    finding the missing positives, done on these types of data is usually thought
    of as one-class collaborative filtering (OCCF).  OCCF can be viewed as an
    extreme case of class imbalance, in which the balance is only distributed over
    one class. \marginpar{checkout Extreme re-balancing for svms: a case study
    maybe}

\subsubsection{Common OCCF Scenarios}
    Some of the most common scenarios where the OCCF problems occurs are:
    Bookmarking, click history, product purchase, "like" and news reader.  The data
    produced from user feedback from all these scenarios can be on the binary form.

\subsection{Different approaches}
    To handle the problem with the sparse data mixed with the ambiguous missing
    data, several strategies has been proposed.

\subsubsection{Negative ratings}
    Since one of the main issues are with the missing data, a natural approach
    would be to gather more.  One way of doing so is by asking the user to rate
    more items.  This can be done through forcing the user to rate a set of
    predetermined items and/or produce negative ratings to uninteresting items.
    The issue with this approach is that putting the rating burden onto the user
    has shown to produce negative user
    experience~\cite{Kelly:2003:IFI:959258.959260}

\subsubsection{All missing as negative (AMAN)}
    One naive approach is to view all the missing values as negative values.
    Thereby saying all web pages ignored by the user are unwanted pages.  One issue
    with this approach is that it will render examples which are positive, but
    unknown, as false negatives.

\subsubsection{All missing as unknown (AMAU)}
    Another naive approach is to go in the opposite direction.  Viewing all missing
    values as unknown, thereby only utilizing the known values when recommending,
    the predictions on the unknown values will only be positive.  The data in an
    OCCF problem is also usually very sparse, therefore using only the positive
    examples will in many cases lead to an incomplete view of the data, and quality
    reduced recommendations.

\subsubsection{Weighted low-rank approximation}
    \cite{pan2008} \cite{Nati03weightedlow-rank}
    The idea behind this approach is to distribute different weights to the unknown
    values.

    More specifically, given two matrices, one rating matrix $R = SxC$, where $S$
    is a list of $m$ items, $S = {s_{1},...s_{m}}$ and $C$ is a list of $n$ users,
    $C = {c_{1}, ... c_{n}}$.
    $R$ has a corresponding weight matrix $W$, where $S$ is a list of $m$ items, $S
    = {s_{1},...s_{m}}$ and $CWz$ is a list of $n$ users, $C = {c_{1}, ... c_{n}}$.
    The values in $R$ are either 0 or 1, and the values in $W$ are between 0 and 1.
    With these two matrices, weighted low-rank approximation is meant to find a low
    rank matrix $X$.  Done through the Frobenius norm, which is minimizing the sum
    squared differences to the target matrix~\cite{frobeniusNorm}.  Other
    approaches to the weighting issue has been taken, such as low-density
    non-negative matrix factorization~\cite{Sindhwani:2010:OMC:1933307.1934641}.

    \begin{equation}
        J(X) = \sum_{mn} W_{mn}(R_{mn} - X_{mn})^2
        \label{equation:frobenius}
    \end{equation}

    Equation~\ref{equation:frobenius} can be optimized and solved efficiently
    though the use of wighted ALS~\citep{Koren2009}.  The positive values are set
    to 1 in the $R$ matrix, and the negative set to 0.
    Since the positive values have a high certainty of being correct, the
    corresponding wight from the matrix $W$ is set to 1.  For the unknown values
    the corresponding weight is set after a weighting schema.  Where the weight is
    lowered for more certain negatives.  This weight is between 0 and 1.  Another
    approach to handling the

    \begin{table}[H]
        \centering
        \begin{tabular}{l|l|l}
          \emph{Schemes}      & \emph{Pos Examples} & \emph{Neg Examples} \\ \hline
          Uniform               & $W_{mn} = 1$ & $W_{mn} = [0,1]$ \\ \hline
          User-Oriented         & $W_{mn} = 1$ & $W_{mn} = UO(\sum_{n} R_{mn})$ \\ \hline
          Item-Oriented         & $W_{mn} = 1$ & $W_{mn} = IO(m - \sum_{n} R_{mn})$ \\ \hline
          User-Item interaction & $W_{mn} = 1$ & $W_{mn} = E(I)$  \\ \hline
          User-Item similarity & $W_{mn} = 1$ & $W_{mn} = S(I,U)$  \\
        \end{tabular}
        \caption[Weighting Schemes]{Different ways of weighting ratings suggested by \cite{pan2008}}
        \label{table:WeightingSchemes}
    \end{table}

    Different weighting schemes are show in~\ref{table:WeightingSchemes}.

    The uniform approach considers all negative examples in the same way, and
    thereby assigns the same weight to all the negative examples.  The
    user-oriented scheme assumes that if a user has more ratings, the negative
    examples can be weighted to be more negative.  The item-oriented assumes that
    if there are more positive example for an item, the missing data is negative
    with a lower probability.  The last scheme, the user-item interaction
    approach, takes into consideration the events on the item to be considered.
    For instance clicks and views.

    \paragraph{User-Item similarity} % (fold)
        \label{subp:user_item_similarity}
        In the user-item similarity approach, the items content of the items and from the users are extracted based on the examples in the data where the positive examples are set to 1.
        From this there is built models for the users and the item.
        The similarity between the user and the item is then used to give the negative examples a weight~\cite{yuan2013}.

\subsubsection{Negative example sampling~\cite{pan2008}}
    In many cases the missing values are in fact negative values.  This approach
    will i most cases lead to a large rating matrix, and therefore high
    computational costs.  Therefore, instead of using all the ratings in the
    ratings matrix $R$, only all the actual positive values are selected.  This is
    combined with a subset of the presumed negative values.  This subset is based
    on a sampling probability matrix $P$.

    There are different sampling schemes.
    Using the same schemes as from weighted low rank approximation.

\subsubsection{Group Bayesian personalized ranking (GBPR)~\cite{Pan:2013:GGP:2540128.2540516}}
    Utilizing rich user interaction.  Group preference is the preference score of a
    group of user on an item.  GBPR assumes that the group preference is stronger
    than the observed user preference.

\subsubsection{Incorporating Rich User Information~\cite{deLace2010,Li2013}}
    When dealing with implicit feedback extra information is usually available
    regarding the user and item.  For instance search query, click history, view
    time and purchase history.  Two ways of incorporating this information has been
    proposed in~\cite{deLace2010}.  One is through linearly combining cores from
    the different sources, and the other is through embedding user information into
    collaborative filtering.

% \subsubsection{Em algorithms to predict negative examples}
    % \cite{Nati03weightedlow-rank}
    % % \todo{check out the approaches}
    % PEBL: positive example based learning for web page classification using SVM
    % Building text classifiers using positive and unlabeled examples
    % Presence-only data and the EM algorithm

    % \subsubsection{Low-density non-negative matrix factorization (ldNMF)}
    % \cite{Sindhwani:2010:OMC:1933307.1934641}
    % arg min
    % J W, H, {y ij } (i,j)∈U =
    % W ≥0,H≥0
    % y ij ∈{0,1},(i,j)∈U
    % λ W
    % 2
    % F
    % + γ H
    % 2
    % F
    % C ij V (X ij , w i T h j )
    % +
    % (i,j)∈L
    % C ij V (y ij , w i T h j )
    % +
    % (i,j)∈U
    % % \todo{make equation}
    % Equation.
    % $R = SxC$ % \todo{0 or 1} is the rating matrix, where $S$ is a list of $m$ items, $S = {s_{1},...s_{m}}$ and $C$ is a list of $n$ users, $C = {c_{1}, ... c_{n}}$.
    % $L$ is the set of positive ratings, while $U$ is the set of unlabeled rating.
    % $W$ and $H$ are the latent factors.
    % $V$ is a loss function (squared loss or generalized KL-divergence).
    % $C$ is the entry specific costs.
    % γ ≥ 0 and $λ$ tradeoff the regularizers againts the fata-fit terms.

\subsection{Discussion}
% todo discuss
