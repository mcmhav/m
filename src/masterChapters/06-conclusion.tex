% !TEX root = ../report.tex

\chapter{Conclusion}
\label{chap:conclusion}

\section{Main results of this work}

% Our proposed system and its components
In this thesis we have proposed a new system for making recommendations using
an extremely sparse dataset with implicit feedback. The proposed system
consists of four core functions:

\begin{itemize}
	\item Generating implicit ratings from event logs (implicit feedback).
	\item Boosting rating quality by simulating user probabilties with filterbots.
	\item Making recommendations - in light of sparsity, implicit feedback and
	fashion domain.
	\item Evaluation and precision metrics.
\end{itemize}

% We have also studied the fashion domain.
In addition, in accordance to set research goals, we have conducted a careful
study of the fashion domain, considering both common user behaviours and the
state of recommender systems. We showed that whilst there exists multiple
competitors, very few provide \textit{personalized recommendations} to its
users, hence this segment was identified as having the largest future potential
for SoBazaar. We identified several unique user properties, consequently making
recommendations more challenging compared to other domains, such as the
importance of subcultures, conformity and recentness of items.

% Summarize our results from the State of the Art.
Furthermore an in-depth \textit{state of the art} analysis were carried out,
focusing in particular on existing or similar implementations of our proposed
components. In addition we present a set of essential methods and techniques
used in modern recommender systems, and which lay the foundation of our thesis.
Great care is taken to discuss and consider all presented methods for both
recommending and evaluating recommendations, with regards to having an
extremely small dataset and designing a solution for the fashion domain.

% First component: generating implicit ratings.
Our first component consists of creating implicit ratings based on a extremely
sparse dataset with \textit{implicit} feedback such as user clicks and item
interactions. First we consider the probability of each item-related event type
to contruct a scoring scheme. Then, for every event exhibited by a user on an
item we then calculate the maximum score possible based on the event type and
various features such as recentness, price and popularity. Every feature is
given a carefully selected penalization function controlling the score,
designed to account for observed behaviours in the domain.

% Second component: filterbots.
Our second component consists of creating pseudo users or filterbots in an
attempt to \textit{mitigate} the cold start problem. These pseudo users rate
items algorithmically according the item-attributes or by aggregating rating
information. A few such examples includes a \textit{PopularityBot} that rate
items based on their popularity, \textit{BrandBots} that gives all items of a
brand a maximum rating and so on. We tested out different filterbot combinations
for all three cold-start scenarios, disappointingly we did not find the filterbots
to improve the cold start performance of the system.

% Third component: recommendation.
Our third component is the system that takes ratings as input and outputs recommendations.
We tested a wide array of different recommender systems on our dataset such as simple
non-personalized approaches, one-class collaborative filtering methods and more sophisticated
latent factor models. The non-personalized and one-class collaborative filtering methods
was used as a baseline for our implicit rating experiments. We found ALS-WR, a latent
factor method for implicit feedback, to be a good fit for our implicit ratings.

% Fourth component: evaluation.
Our fourth component we came up with an set of evaluation metrics to measure the
overall quality of the recommender systems. Evaluating recommender systems using implicit
feedback differs from traditional recommender system evaluation, simply using RMSE was not
enough. We determined that a combination of accuracy and rank-accuracy metrics was the best
fit for our top-20 recommendation task. AUC measures the overall quality of the recommender
system while $MAP@20$Â and our own unique event specific measurements measure the systems
ability to rank the top 20 recommendations.


% How the proposed system performs
The proposed system outperformed all other methods tested both in terms of
accuracy and its ability to rank the top results. Our results also indicate:
%TODO - %Sigmoid = Count
%Recentness works!
%Popularity better than price!
%Results should be further verified through online experiments
\marginpar{TODO: mention increase in accuracy and ranking ability}

% Concluding thoughts
Based on findings presented in this thesis, it is concluded that despite making
recommendations for a difficult domain, with a extremely sparse dataset and
without any negative or explicit feedback -- a promosing result was still made.
Using ideas, methods and insight from this thesis we believe that a well
functioning recommender system for use in a production environment is both
possible and would yield multiple competitive advantages. In addition, we have
presented the current state of the art in both fashion recommending and
implicit rating generation, from where we draw the conclusion that although
little research in the area exist today, the potential is great and making
recommendations based on user behaviours will in future recommender system be
inevitable.

%Recommender systems are arguably one of the trendiest uses of data science
%startups today. However, with the exception of very rare cases such as Pandora
%\footnote{http://www.pandora.com/}, it is not the killer feature of your
%application which make users flock to you. The reason it works great for
%Amazon and Netflix is because that have \text{millions} of titles and large
%existing user bases. Presenting users with recommended movies and products
%increase usage and sales, but does not create either to begin with.
%
%The more data the better. With little or no data you won't be able to make
%recommendations \text{at all}. Unless you have the users, domain expertise,
%algorithm development skill, massive inventory and frictionless user data
%entry your recommender system will not be \emph{the milkshake that brings all
%the boys to the yard}. Instead the focus should be on building your core
%product, optimizing your e-commerce funnel, growing your user base, developing
%user loyalty and growing your inventory. In the meantime you can drive
%serendipitous recommendations simply by using a combination of most popular
%content and editors.

\section{Future Work}

As this thesis concerns itself with multiple different segments of modern
recommender systems, there are a range of future work which could yield
both interesting and auspicious results. Consequently we divide this section
into these segments, looking at possible future work for each of them.

\subsubsection{Generating implicit ratings}

There are lot of research to still be done in conversion from implicit feedback
to implicit ratings. Primarily one should try to get more concrete results by
either performing user studies or evaluating various generated ratings in an
online system.

By incorperating a user-study or similar ways for active users to explicitly
convey feedback on items, further studies into building regression models based
on an ordinal scale should be performed -- especially using features found in
the fashion domain. Some work, as we have seen in this thesis, has been done in
this area already~\cite{parra2011walk}~\cite{parra2011implicit}, but as they
too conclude more quantiative results should be presented to the research
community.

Extending the models in this thesis with regards to penalization of features
can prove rewarding. Most features are linearly penalized, except for
recentness, but here more sophisticated functions taking more domain and
dataset specific challenges can be taken into account.

Using other features such as brand preference, demographics and fashion trends
could also prove beneficial in terms of rating quality. Finally, a more
sophisticated way of combining a set of implicit ratings should be developed --
although this is difficult due to the lack of a ground truth, one could e.g.
look at AUC-scores in the last stage of our pipeline (see
Sectian~\ref{sec:app-overview}) and optimize for this metric.

\subsubsection{Cold-start issues}

In terms of cold-start issues further work should be done in order to improve
item classification, consequently creating a denser and more precise product
database. Although this is closely related to natural-language processing, many
artificial intelligence techniques has the potential of e.g. correctly
identifying attire type, style and color based on a longer item description.

% Demographic filtering as a solution to the cold-start user problem?
% TODO: Some future work with regards to filterbots?

\subsubsection{Recommending based on implicit feedback}

We believe it would be interesting to look into how one could implement a
reward attribute for the items, that factors in how much the retailer will
profit from its sale.

\begin{equation}
ExpectedReturn_i = P(Sale_i) * Reward(i)
\end{equation}

The question then, is how this information can e.g. be used/incorporated into
the recommender to increase profits without sacrificing (too much or any) user
satisfaction by recommending more \emph{expensive} items to the user.

In terms of implicit feedback a further study into methods especially tailored
for generated ratings from implicit feedback should be performed. As we have
primarily used open-source pre-built implementations of most recommender
methods in this thesis, due to time contraints, a study focusing on only this
component of the system could prove rewarding.

%TODO: Recommender systems for anonymous users - Context - move to cold start?

\subsubsection{Evaluation implicit feedback}

As we have seen, evaluation should ideally be done in two compoenents of our
system -- both when generating ratings and making recommendations. We have
already mentioned how online evaluationg and user-studies may aid us in the
first scenario, but in the second a larger study concerning other implicitly
based methods (see Figure~\ref{overview-eval}) should be conducted.

Further, it would be interesting to study the effects personalization has on
the implicit factors. We hypothesize that by creating accurate recommendations
new user patterns will emerge, that either can worsen or improve future
recommendations. In addition, it could be highly interesting to experiment with
personalized weights to implicit factors, as perhaps some users are more
brand-aware than others who concern themselves more with the price, and vica
versa.

Finally a study on the relationship between matrix factorization methods such
as SVD and our manual feature selection could be carried out, as they are
highly synonymous.

\subsubsection{Future studies on SoBazaar data}

With regards to the SoBazaar data our main desire is to see future analysis
done when the data are more dense and user patterns going over multiple years
emerges. Doing future studies in the fashion domain should be highly rewarding
and has (as we have seen in Table~\ref{table:ecommerceCommpetiros}) a huge
potential. Especially one should confirm claims made on fashion domain and user
behaviours declared in this thesis, by performing user-studies or other forms
of quantitative analysis.

A more in-depth study on finding items with a high similarity to the one
currently viewed, should be performed.

By doing A/B-testing or Multi-Armed Bandit experiments (see
Section~\ref{sec:online-eval}) it could be studied to which degree adding a
scale between 1 to 5, replacing the current heart-icon, hurt or boost the total
number of item-interactions.

Methods for better extracting data from the various brand-stores should be
identified. Per Table~\ref{table:extracted-content-features} many items were
\textit{featureless} due to poor descriptions and metadata -- which in turn
weaken the final results.

By adding alternative user interfaces such as a \textit{tinder-like hot or not}
approach (see Section~\ref{par:competitors_recommendation_overview}) one should
observe their effects on both the number of item-interactions and quality of
implicit feedbacks. Further studies into \textit{how} one can add negative
feedback to the system should also be considered.

Contextual item-to-item recommendations should be considered implemented to
display related items to anonymous users. Instead, in todays application the
current recommends based on the metric "People who love this also love \dots".

As shown in \cite{meyer2012recommender} most successful commercial recommender
incorporate multiple sources of information. The following information sources
should therefore be examined more closely to assess if they can add any value
to the system:

\begin{itemize}
	\item Social and information (friend and \textit{in-app following}-network).
	\item Content information (type of attire, style, color, brand, subculture).
	\item Demographic information (age, sex, interests and more).
\end{itemize}

%%%% THE END %%%%%
