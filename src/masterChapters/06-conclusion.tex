% !TEX root = ../report.tex

\chapter{Conclusion}
\label{chap:conclusion}

\section{Main results of this work}

% Our proposed system and its components
In this thesis we have proposed a new system for making recommendations using
an extremely sparse dataset with implicit feedback. The proposed system
consists of four core functions:

\begin{itemize}
	\item Generating implicit ratings from event logs (implicit feedback).
	\item Boosting rating quality by simulating user probabilities with filterbots.
	\item Making recommendations - in light of sparsity, implicit feedback and
	fashion domain.
	\item Evaluation and precision metrics.
\end{itemize}

% We have also studied the fashion domain.
In addition, in accordance to set research goals, we have conducted a careful
study of the fashion domain, considering both common user behaviors and the
state of recommender systems. We showed that whilst there exists multiple
competitors, very few provide \textit{personalized recommendations} to its
users, hence this segment was identified as having the largest future potential
for SoBazaar. We identified several unique user properties, consequently making
recommendations more challenging compared to other domains, such as the
importance of subcultures, conformity and recentness of items.

% Summarize our results from the State of the Art.
Furthermore an in-depth \textit{state of the art} analysis were carried out,
focusing in particular on existing or similar implementations of our proposed
components. We here set forth a set of essential methods and techniques used in
modern recommender systems which lay the foundation of our thesis.  Great care
is taken to discuss and consider all presented methods for both recommending
and evaluating recommendations, with regards to having an extremely small
dataset and designing a solution for the fashion domain.

% First component: generating implicit ratings.
Our first component consists of creating implicit ratings from with
\textit{implicit} feedback such as user clicks and item interactions. Initially
we consider the probability of each item-related event type to construct a
scoring scheme. Then, for every event exhibited by a user on an item we then
calculate the maximum score possible based on the event type and various
features such as recentness, price and popularity. Every feature is given a
carefully selected penalization function controlling the score, designed to
account for observed behaviors in the domain.

% Second component: filterbots.
Our second component consists of creating pseudo users or filterbots in an
attempt to \textit{mitigate} the cold start problem. These pseudo users rate
items algorithmically according the item-attributes or by aggregating rating
information. Two such bots include a \textit{PopularityBot} who rate items
based on their popularity and a \textit{BrandBot} who gives all items of a
brand the maximum rating. We tested out different filterbot combinations for
all three cold-start scenarios, disappointingly we did not find the filterbots
to improve the cold start performance of the system, but primarily credit this
to the dissatisfactory quality of product metadata and the lack of demographic
details about the users.

% Third component: recommendation.
Our third component takes ratings as input and outputs
recommendations. We tested a wide array of different recommender algorithms on
our dataset such as simple non-personalized approaches, one-class collaborative
filtering methods and more sophisticated latent factor models. The
non-personalized and one-class collaborative filtering methods was used as a
baseline for our implicit rating experiments. We found ALS-WR, a latent factor
method for implicit feedback, to perform very well in our domain and given our
evaluation criterias.

% Fourth component: evaluation.
In our fourth component we found a set of evaluation metrics to measure the
overall quality of the recommender systems. Evaluating recommender systems
using implicit feedback differs from traditional recommender system evaluation
and simply using RMSE was not applicable. We determined that a combination of
accuracy and rank-accuracy metrics was the best fit for our top-20
recommendation task.  AUC measures the overall quality of the recommender
system while $MAP@20$ and our own unique event specific measurements measure
the systems ability to rank the top 20 recommendations.

% How the proposed system performs
The proposed system outperformed all other methods tested both in terms of
accuracy and its ability to rank the top results for a time-based split.
Ordering and Recency performed particularly well scoring an AUC of 8\% higher
than the best binary method in addition being able to recall more clicks and
wants and increase the ranking quality. The improvements over the
non-personalized most popular recommender was a 237\% increase in recall of
wanted items and an increase from 0\% recall of purchased items to 8.33\% for
ordering. For the random split the results were less conclusive.  Here the
blend combining recentness, price and popularity, scored an AUC that was 4.3\%
higher than the best binary method and was able to recall both more wanted
items and purchases. However, user-based kNN managed to achieve a higher
$MAP@20$ scores when considering wanted and purchased items, making this
segment of our results inconclusive. Our results give strong indication that
recentness is an important factor in the fashion domain. We also found that the
price too consistently give better results than considering item-popularity,
which might give some indication that this is a more important feature for
users in this domain. Due to the limited size of our dataset we are careful to
not make grand claims about the results, and believe they should be verified
through online experiments or user studies.

% Concluding thoughts
Based on findings presented in this thesis, it is concluded that despite making
recommendations for a difficult domain, with a extremely sparse dataset and
without any negative or explicit feedback -- a promising result was still made.
Using ideas, methods and insight from this thesis we believe that a well
functioning recommender system for use in a production environment is both
possible and would yield multiple competitive advantages. In addition, we have
presented the current state of the art in both fashion recommending and
implicit rating generation, from where we draw the conclusion that although
little research in the area exist today, the potential is great and making
recommendations based on user behaviors will in the future be inevitable.

\section{Discussion}

In Chapter~\ref{chap:introduction} we introduced a total of 8 research goals
which would lay the foundations of this thesis and guide our efforts towards
the restulting system. We re-iterate them here:

\begin{itemize}
\item \textbf{G1}: Gain a better understanding of the fashion domain.
\item \textbf{G2}: Identify the specific challenges of making fashion recommendations.
\item \textbf{G3}: Study how existing technologies can be adapted to mitigate or
overcome these challenges.
\vfill
\item \textbf{G4}: Study existing solutions to the cold-start problem.
\item \textbf{G5}: Identify the best suited methods with regard to both application
feedback and domain.
\vfill
\item \textbf{G6}: Explore the existing solutions of how to infer user preference from
implicit feedback data.
\item \textbf{G7}: Identify different methods of combining various event types into
\textit{implicit ratings}.
\item \textbf{G8}: Find metrics in order to evaluate the \emph{implicit ratings} and
recommendations.
\end{itemize}

We will in this section provide an overview on how these research goals were
attempted met and to which degree they were fulfilled. One should however note
that more detailed analyses are issued throughout the thesis -- for G1, G2 and
G3 consult Section~\ref{subsec:fashion-theory} and
Chapter~\ref{chap:thesobazaardata}; for G4 and G5 see
Section~\ref{sec:cold-start-discussion}; and G6, G7 and G8 are discussed at
length in Section~\ref{sec:implicit}, Section~\ref{sec:implementation-implicit} and
Section~\ref{sec:experimental-plan}, respectively.

\subsection{G1, G2 and G3: Fashion domain and recommendation systems}
\label{sec:fashion-discussion}

By thorough examination and analysis of the data combined with an extensive
literature review on the fashion domain we came to the main conclusion that
time, subcultures, trends, brands and price were important features to
incorporate into a fashion recommender. Additional features should be analyzed
and verified by having denser data over a longer timespan, in order to see
more features and statistically significant numbers.

Analyzing the SoBazaar data, it became apparent that sparsity were not only a
problem in number of users, but also looking at the amount of items and their
connected interactions. Recentness was shown to have a great effect on user
interactions, as well as it was demonstrated that yielding an increased number
of clicks on an item augment the probability of purchase in a positive way.

In terms of recommender systems in the fashion domain we determine that
\textit{time} should play an important role in order to determine preferences.
A decaying factor on feedback on both item popularity and based on season
should be implemented, in order to handle the items' loss of attention over
time due to changes in trends or climate. Demographics and social networks
should also be established, and be used as a user-classifier, as they affect
fashion preferences.

By these conclusions we argue that \textbf{Goal G1, G2 and G3} were
\textbf{fulfilled}.

\subsection{G4 and G5: Cold-start issues and sparsity}
\label{sec:cold-start-conclusion-discussion}

Through our literature review, we closely examined five different classes of
solutions to the cold-start problem. Namely trust-aware recommender system,
filterbots, seed users, interview process and hybrid methods. The reason for
including multiple methods that never were used, was due to uncertainty
regarding what data would become available during the project. Trust-aware
recommender system and hybrid methods in particular could never be tested out
due to a lack of social/demographic data, which we were hoping to get access
to.

After closely examining the different methods we concluded that both filterbots
and content-boosted hybrid methods could provide a possible solution for our
specific scenario. However, only modest results were achieved with our
solution, and we largly attribute this to the quality of product metadata and
the lack of demographic data on users. Agarwal et. al. \cite{Agarwal2009} used
13 filterbots in their experiments, where 11 of them were based on demographic
information, which underlines the importance of this segment.

However, we identified multiple existing solutions which, with better data,
should mitigate most cold-start issues in the fashion domain and the SoBazaar
application. In addition a successful implementation of filterbots were carried
out, serving as an important proof of concept. Consequently we argue that
\textbf{Goal G4 and G5} were \textbf{fulfilled}.

\subsection{G6, G7, G8: Making recommendations with implicit feedback}
\label{sec:implicit-discussion}

We identified multiple existing solutions for inferring user preference from
implicit feedback, however a common denomiatior between a majority of them were
the additional need for explicit feedback as well. As neither user studies nor
online evaluation could be carried out, we proposed a solution based on dataset
properties and domain-specific feature selection.

Our results in this regard indicate the importance of implicit feedback, where
we obtain an even and robust distribution of ratings that performs well in all
offline evaluation scenarios. In addition we argue that found properties is
especially important for the fashion domain and that, even in an environment
with explicit feedback, it should be utilized in order to infer user
preferences.

As have been highlighted in multiple studies on implicit feedback, there exist
no good evaluation schemes for offline studies, especially when no explicit
feedback is available. Consequently, we strongly advise to either conduct
user-studies on users inhabiting interesting and representative user-patterns
or having a framework for online-evaluation available in order to guide both
method and parameter choices.

Nonetheless, we evaluate our implicit ratings looking at performance using the
same parameters in all later components, and still achieve a satisfactory
result proving the effectiveness of our implementation. This, combined with a
comprehensive study of possibilities with regards to implicit feedback leads us
to argue that \textbf{Goal G6, G7 and G8} were \textbf{fulfilled}.

\section{Future Work}

As this thesis concerns itself with multiple different segments of modern
recommender systems, there are a range of future work which could yield
both interesting and auspicious results. Consequently we divide this section
into these segments, looking at possible future work for each of them.

\subsubsection{Generating implicit ratings}

There are lot of research to still be done in conversion from implicit feedback
to implicit ratings. Primarily one should try to get more concrete results by
either performing user studies or evaluating various generated ratings in an
online system.

By incorporating a user-study or similar ways for active users to explicitly
convey feedback on items, further studies into building regression models based
on an ordinal scale should be performed -- especially using features found in
the fashion domain. Some work, as we have seen in this thesis, has been done in
this area already~\cite{parra2011walk}~\cite{parra2011implicit}, but as they
too conclude more quantitative results should be presented to the research
community.

Extending the models in this thesis with regards to penalization of features
can prove rewarding. Most features are linearly penalized, except for
recentness, but here more sophisticated functions taking more domain and
dataset specific challenges can be taken into account.

Using other features such as brand preference, demographics and fashion trends
could also prove beneficial in terms of rating quality. Finally, a more
sophisticated way of combining a set of implicit ratings should be developed --
although this is difficult due to the lack of a ground truth, one could e.g.
look at AUC-scores in the last stage of our pipeline (see
Section~\ref{sec:app-overview}) and optimize for this metric.

\subsubsection{Cold-start issues}

In terms of cold-start issues further work should be done in order to improve
item classification, consequently creating a denser and more precise product
database. Although this is closely related to natural-language processing, many
artificial intelligence techniques has the potential of e.g. correctly
identifying attire type, style and color based on a longer item description.

\subsubsection{Recommending based on implicit feedback}

We believe it would be interesting to look into how one could implement a
reward attribute for the items, that factors in how much the retailer will
profit from its sale.

\begin{equation}
ExpectedReturn_i = P(Sale_i) * Reward(i)
\end{equation}

The question then, is how this information can e.g. be used/incorporated into
the recommender to increase profits without sacrificing (too much or any) user
satisfaction by recommending more \emph{expensive} items to the user.

In terms of implicit feedback a further study into methods especially tailored
for generated ratings from implicit feedback should be performed. As we have
primarily used open-source pre-built implementations of most recommender
methods in this thesis, due to time constraints, a study focusing on only this
component of the system could prove rewarding.

\subsubsection{Evaluation implicit feedback}

As we have seen, evaluation should ideally be done in two components of our
system -- both when generating ratings and making recommendations. We have
already mentioned how online evaluation and user-studies may aid us in the
first scenario, but in the second a larger study concerning other implicitly
based methods (see Figure~\ref{fig:overview-eval}) should be conducted.

Further, it would be interesting to study the effects personalization has on
the implicit factors. We hypothesize that by creating accurate recommendations
new user patterns will emerge, that either can worsen or improve future
recommendations. In addition, it could be highly interesting to experiment with
personalized weights to implicit factors, as perhaps some users are more
brand-aware than others who concern themselves more with the price, and vica
versa.

Finally a study on the relationship between matrix factorization methods such
as SVD and our manual feature selection could be carried out, as they are
highly synonymous.

\subsubsection{Session Analysis}

As we saw in Section~\ref{sec:sessionPatterns}, the sessions can be used to infer usage patterns to better the recommendations. One way of doing so is trough utilizing Markov Hidden Models~\cite{rabiner1986introduction} to predict state accessing, which could be an interesting addition to the implicit data, to better make personalized recommendations.


\subsubsection{Future studies on SoBazaar data}

With regards to the SoBazaar data our main desire is to see future analysis
done when the data are more dense and user patterns going over multiple years
emerges. Doing future studies in the fashion domain should be highly rewarding
and has (as we have seen in Table~\ref{table:ecommerceCommpetiros}) a huge
potential. Especially one should confirm claims made on fashion domain and user
behaviors declared in this thesis, by performing user-studies or other forms
of quantitative analysis.

A more in-depth study on finding items with a high similarity to the one
currently viewed, should be performed.

By doing A/B-testing or Multi-Armed Bandit experiments (see
Section~\ref{sec:online-eval}) it could be studied to which degree adding a
scale between 1 to 5, replacing the current heart-icon, hurt or boost the total
number of item-interactions.

Methods for better extracting data from the various brand-stores should be
identified. Per Table~\ref{table:extracted-content-features} many items were
\textit{featureless} due to poor descriptions and metadata -- which in turn
weaken the final results.

By adding alternative user interfaces such as a \textit{tinder-like hot or not}
approach (see Section~\ref{par:competitors_recommendation_overview}) one should
observe their effects on both the number of item-interactions and quality of
implicit feedbacks. Further studies into \textit{how} one can add negative
feedback to the system should also be considered.

Contextual item-to-item recommendations should be considered implemented to
display related items to anonymous users. Instead, in todays application the
current recommends based on the metric "People who love this also love \dots".

As shown in \cite{meyer2012recommender} most successful commercial recommender
incorporate multiple sources of information. The following information sources
should therefore be examined more closely to assess if they can add any value
to the system:

\begin{itemize}
	\item Social and information (friend and \textit{in-app following}-network).
	\item Content information (type of attire, style, color, brand, subculture).
	\item Demographic information (age, sex, interests and more).
\end{itemize}

%%%% THE END %%%%%
