%As  !TEX root = ../../report.tex
\section{Generating implicit ratings}
\label{implementation-implicit}

In this section we continue solving the problem of generating ratings based on
implicit feedback found in analytics logs, as defined in
Section~\ref{implicit-feedback}. Our goals are two-fold:

\begin{itemize}
  \item Find novel ways of creating implicit ratings, remedying as many
  weaknesses and challenges, depicted in Section~\ref{implicit-weaknesses}, as
  possible
  \item Customize existing and new algorithms to our fashion domain, described
  in Section~\ref{motivation}
\end{itemize}

The most important factor when creating ratings is to understand which implicit
data are available and their implications on user preferences. In order to best
understand the data one should do a quantitative study as presented in
Chapter~\ref{sobazaar-data}, but always keeping in mind the domain in question.
When an understanding is obtained one can begin selecting features capturing
the wanted properties and use these generalizations in order to generate
ratings for different users inhabiting unique patterns and product
interactions.

Then, upon evaluation of conversion features we can do an intitial analysis
without any metrics by attempting to answer the question \textit{does this
generalization capture the domain and data properties?} 
One such generalization, often done, is counting the number of a specified
activity on an item, correlating it with preference. In the case of SoBazaar
we've seen that a higher number of clicks yields a higher probability of
purchasing an item, thus we can use the number of clicks as a feature in
generating ratings - correlating a higher number of clicks to a higher rating.

Other properties, which we will discuss in this section and consequently
utilize, found in the \textit{fashion store aggregation} domain are:

\begin{itemize}
  \item Items have a short lifespan, due to:
  \begin{itemize}
    \item Seasons
    \item Fashion and trends
    \item Sales and price fluctuations
  \end{itemize}
  \item Items are not bought regularily, as with food and other convenience
  products
  \item Users are cost and brand-aware
\end{itemize}

Given a good set of chosen features we should, for all users that have
interacted with various items, obtain a well-distributed list of ratings - and
with more implicit feedback available for a user, we should obtain a higher
probability of the user having an unique set of ratings. This is easily seen in
the scenario where we do not consider social-graphs between users, and we have
two users $u_1$ and $u_2$ who has the equal implicit feedback - e.g. they
viewed the same items. If we only use global features, such as item popularity,
we have no way of giving unique ratings to the two users. However, if we
instead look at user-features such as \textit{when}Â did the users last look at
the items and \textit{in which order}, we have a higher probability of
obtaining unique sets of ratings.

When ratings are not explicit, the implicit ratings becomes the recommender
systems equivelent of a ground truth and all later stages in the recommender
pipeline (See Section~\ref{}) are dependent on the ratings representing a users
preferences. This highlights the importance of generating high quality ratings
and selecting good features and methods for doing so.

\subsection{Linearily penalizing features}

In Section~\ref{implicit-binary-domains} Pranab Ghosh proposes a global rating
mapping without any specific justification of why the different values are
chosen~\cite{pkghost2014implicit}. In order to use this method we wanted our
weighting of various events to be grounded in statistical properties found in
the dataset. Further we would like to create ratings on a continious scale
between a min and max-value for the given event, not manually define levels of
scores. This way we could use a \textit{penalization function}, that based on
our selected feature ensured an even distrubution between the mininmum and
maximum value for the event in question. For example giving an often clicked
product for a user the maximum value and conversly the minimum value for
infrequent clicks.

To select good weights we thus considered the probability of each event that we
wanted to base our ratings on. These events were the ones having a
\textit{product id} as well as possibly inhabiting the implicit properties
described above. Instead of manually map events to an arbitrary score we used
the probability obtaining the given event type, given all events. Thus, our
score mapping looks like:

\begin{table}[H]
  \centering
  \begin{tabular}{llll}
    \toprule
      Event type & Probability & Min & Max \\
    \midrule
      \textit{product\_detail\_clicked}     & $\frac{25416}{40686} \approx 62$  & 0   & 62  \\[1.5ex]
      \textit{product\_wanted}              & $\frac{13252}{40686} \approx 33$  & 62  & 95  \\[1.5ex]
      \textit{prodcut\_purchase\_intended}  & $\frac{2018}{40686} \approx 5$    & 95  & 100 \\
    \bottomrule
  \end{tabular}
\end{table}

Notice that the total number of events having a product id is 40686, and the
sum of all three fractions is 1, thus covering 100\% of all events.

How then do we distrubute the feature-values  between the min and max limits
above? In our first implementation we use a \textit{linear} function, set in
such a way that $0 \leq p(x) \leq 1$ and $0 \leq x \leq M_u$ where $M_u$ is the
maximal observed value for user $u$ of the feature in question. Hence our
penalization function is defined as:

\begin{equation}
  p(x, u) = \frac{x}{M_u}
\end{equation}

By considering penalization we also implicitly add negative feedback to events.
This is an important aspect to keep in mind when working with implicit
feedback, as discussed in Section~\ref{implicit-feedback} as modern recommender
engines work better when we are assuming ratings are based on both positive and
negative feedback.

Given $p(x, u)$ we formulize an equation for finding $S_e(x, u)$, the score
given to event $e$ after penalization, given a max $M_u$ and min $m_u$ value.

\begin{equation}
  S_e(x,u) = M_e - (M_e - m_e) \cdot p(x, u)
\end{equation}

The last component needed is normalizing the ratings. Which is described in
Equation~\ref{eq-normalization}. And now we have all components ready in order
to do a rating generation. In order to see all parts working together, we
imagine an example where a user has six events on three items, as presented in
the table below. The ratings are normalized between 1 and 5 and the product IDs
are there for illustrative purposes. We choose to look at the number of days
since the user did the event in question as the implicit feature, where $x=0$
means the event was registered today (or as the most recent) and in our example
$x=14$ is the oldest event happening two weeks ago. 

\begin{table}[H]
  \centering
  \begin{tabular}{llllll}
  \toprule
  Event type & Product ID & x (days) & P(x) & Score & Rating \\
  \midrule
  \textit{product\_purchase\_intended}  & 1 & 0   & $\frac{0}{14} = 0.00$  & 100 & 5.00 \\[1.5ex]
  \textit{product\_purchase\_intended}  & 2 & 3   & $\frac{3}{14} = 0.21$  & 98.95 & 4.96 \\[1.5ex]
  \textit{product\_wanted}              & 2 & 7   & $\frac{7}{14} = 0.50$  & 78.5 & 4.14 \\[1.5ex]
  \textit{product\_detail\_clicked}     & 1 & 0   & $\frac{0}{14} = 0.00$  & 62 & 3.48 \\[1.5ex]
  \textit{product\_detail\_clicked}     & 3 & 7   & $\frac{7}{14} = 0.50$  & 31 & 2.24 \\[1.5ex]
  \textit{product\_detail\_clicked}     & 2 & 14  & $\frac{14}{14} = 1.00$ & 62 & 1.0  \\
  \bottomrule
  \end{tabular}
  \caption{Showing penalizations and ratings on example data}
  \label{implicit-ratings-example}
\end{table}

When finally selecting a rating for the user/product pair, we choose the
one yielding the highest value for the given product. Hence for the three items
with IDs 1, 2 and 3 above we obtain the ratings 5.00, 4.96 and 2.24, respectivly.

Using the same method on the SoBazaar dataset yields the following distribution
of ratings, where we group ratings together into 150 different bins - thus
every bin having an interval size of 0.0267:

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{image/dist-recentness-linear}
  \caption{Distribution of ratings using number of days since event as feature
  and a linear penalization function}
\end{figure}

We can see two ratings are widely more popular than others: 3.48 and 1.0. This
makes sense, as every user that has more than two clicks registered are
guaranteed to have the penalizations 1.0 and 0.0 apparent. As this is an
obvious weakness we change our penalizations such that $M_u$ and $m_u$ are not
longer based on the oldest and most recent events for user $u$, but rather the
oldest and newest event in the dataset globally. Changing these factors yield
the following distribution:

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{image/dist-recentness-linear-global}
 \caption{Distribution of ratings using number of days since event, a linear
 penalization function and global min/max feature-values}
  \label{fig:dist-recentness-linear-global}
\end{figure}

This is a much more interesting result, having an more even distribution of
ratings with few gaps. The average rating is \textit{3.29} with a median
\textit{3.37}. The weakness in these results however is easy to spot given the
scenario when a user is absent from the application over a longer time and then
returns. In this scenario all the items the user has previously looked at,
wanted or bought will all suffer from large penalization values - and hence low
ratings, since the x for all items is very high. In addition the method does
not scale well, unless one limit the $M_u$ value, so that the difference
between two adjecent x values are significant. As SoBazaar is a relativly new
application this proved not to be a problem with our experiments, but given a
larger dataset with older events we would recommend testing $M_u = \min(O_e,
L)$ where $O_e$ is the number of days since the oldest event and $L$ is the
limit, set at e.g. 200.

In order to mitigate the returning user problem we adjust our feature to
instead consider the ordering of events for user $u$. This way, given $n$
events registered for this user, the newest event would obtain $x=0$ and the
oldest $x=n$. This yields the following distribution:

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{image/dist-count-linear}
  \caption{Distribution of ratings using ordering of events, and a linear
 penalization function}
  \label{fig:dist-count-linear}
\end{figure}

With much the same average and median values at \textit{3.26} and \textit{3.45}
respectivly, we still have a distribution with a unique pattern where the
ratings are more evenly distributed (the largest bin contains 700 ratings in
the given interval, compared to Figure ~\ref{dist-recentness-linear-global}
where the same number is 1250.)

\subsection{Penalization with logistic functions}

So far we've seen ratings generated by looking at the event recentness,
capturing important factors such as items having a short life-time and users
frequently shopping for different occasions and hence different types of
clothes. However, we want to improve the penalization function in order to
capture the following properties in our domain:

\begin{itemize}
  \item Recent events should count more towards a good rating, compared to old
  events.
  \item Seasons change at a fixed interval, and clothes goes out of season in
  the matter of weeks.
  \item A user may look at multiple clothes at once, comparing them and finding
  them all quite interesting.
\end{itemize}

When using a linear function the difference in penalization between the two
most recent items are equal to the difference between the oldest two items.
However, intuitively we consider a user to have multiple relevant items
concurrently and we know that in domains such as technology, fashion and other
consumer-products an item has an age of relevancy, somewhat metaphoric to a
seasonal threshold. An example of this could be a fashion store recommending
warm clothes in the months between December to March, but then want to "change"
product pool based on the users behaviours â who are probably looking for
lighter clothes (changing season).

In order to mimic this behaviour we introduce a logistic function, which is a
mathematical function having an "S" shape and a common special case of the more
general sigmoid-function. In its most simplest case the logistic function is
defined as:

% Vertical alignment of equation and plot.
\begin{figure}[H]
  \centering
  \noindent\begin{minipage}{.45\textwidth}
    \begin{tikzpicture}
      \begin{axis}
      \addplot[black,xlabel=$x$,ylabel=$f(x)$] {1/(1+exp(-x))};
      \end{axis}
    \end{tikzpicture}
  \end{minipage}
  \begin{minipage}{.45\textwidth}
  \begin{align}
    \label{logistic-function}
    f(x) = \frac{1}{1+\exp^{-x}}
  \end{align}
  \end{minipage}
  \caption{Logistic function having a S-shape with y-values ranging
  from 0 to 1.}
\end{figure}

Here the value of $f(x)$ is asymptotically limited between 0 and 1, dependent
on the value of $x$. The steepest point of the curve happens when $x=0$. By
adjusting the exponent of $e^{(-x)}$ we can skew the curve in order to map to our
data, giving us a \textit{function of relevancy} ranging from an item being
very relevant ($f(x)=0$) and not relevant ($f(x)=1$).

By adding two variables to the logistic function we can fine tune both the
steepness and range of $f(x)$. Hence we adjust Equation~\ref{logistic-function}
to include $s$, the \textit{steepness coefficient}, and $c$, the \textit{shift
coefficient}.

\begin{equation}
  p(x) = \frac{1}{1+\exp^{-s(x - c)}}
\end{equation}

In the standard sigmoid function these are $1$ and $0$ respectively, but by
adjusting $s$ closer to 0 we decrease the steepness, creating a more gradual
curve. Setting the $c$ to a larger number we shift the steepest point of the
curve to $x=c$, hence if we set $c$ to $20$, the steepest point (largest
acceleration) in our curve would be located when $x=20$.

We can manually try to set the steepnes and shift coeffiecients based on the
behaviour seen in the dataset provided. Using the data provided in
Table~\ref{implicit-ratings-example} we can again try to calculate the ratings
and penalizations. We set the steepness coefficient to be $0.8$, thus having a
curve that is not too steep yielding a good distribution. This constant works
well when the shift coefficient is low ($c \lessapprox 10$), however if the
shift coefficient increases the steepness should decrease. In our dataset we
found finding a fixed ratio between the steepness and shift worked best. The
shift is set at $M/2$, where $M$ equals the number of days between the oldest
and most recent event, in our example equalling 7.

\begin{table}[H]
  \centering
  \begin{tabular}{llllll}
  \toprule
  Event type & Product ID & x (days) & P(x) & Score & Rating \\
  \midrule
  \textit{product\_purchase\_intended}  & 1 & 0   & $\frac{1}{1 + \exp^{-0.8(0*7)}} = 0.00$  & 100 & 5.00 \\[1.5ex]
  \textit{product\_purchase\_intended}  & 2 & 3   & $\frac{1}{1 + \exp^{-0.8(3*7)}} = 0.03$  & 99.85 & 4.99 \\[1.5ex]
  \textit{product\_wanted}              & 2 & 7   & $\frac{1}{1 + \exp^{-0.8(7*7)}} = 0.50$  & 78.5 & 4.14 \\[1.5ex]
  \textit{product\_detail\_clicked}     & 1 & 0   & $\frac{1}{1 + \exp^{-0.8(0*7)}} = 0.00$  & 62 & 3.48 \\[1.5ex]
  \textit{product\_detail\_clicked}     & 3 & 7   & $\frac{1}{1 + \exp^{-0.8(7*7)}} = 0.50$  & 31 & 2.24 \\[1.5ex]
  \textit{product\_detail\_clicked}     & 2 & 14  & $\frac{1}{1 + \exp^{-0.8(14*7)}} = 1.00$ & 62 & 1.0  \\
  \bottomrule
  \end{tabular}
  \label{implicit-ratings-example-sigmoid}
\end{table}

Notice how the purchase of product with ID 2 went from $4.96$ in
Table~\ref{implicit-ratings-example} to $4.99$ here, as we have lower
penalization for lower x-values. Equally, the penalizations are equal ($0.50$
and $1.00$) when the x-values are 7 and 14 respectivly. However, while this
works fine in the example above we need to set the ratio between the steepness
and shift coefficient, as manually setting the steepness based on the
shift-coefficient is imprecise and non-scientific. Instead we alter our
logistic function to instead using a ratio $r$ between the two constants:

\begin{equation}
  p(x) = \frac{1}{1+e^{-(r/c) \cdot (x - c)}}
\end{equation}

Here the $c$ equals the steepest point (shift coefficient), and we set it so
that $c = M/2$ where $M$ still being the oldest event globally, as described in
the previous section. In the SoBazaar dataset $M$ was $224$. Using a different
ratio changes the logistic function in the following way:

\newcommand{\sigmoidfixed}[3]{
  % Draws a sigmoid-function.
  % #1 = ratio
  % #2 = max value
  % #3 = scale of image
  \begin{tikzpicture}[scale=#3]
    \begin{axis}[
      ymin=0,ymax=1,
      xmin=0,xmax=#2,
      grid=both,
    ]
    \addplot[
    black,
    xlabel=$x$,
    ylabel=$f(x)$,
    domain=0:#2]
    {1/(1+exp(-(#1/(#2/2))*(x-(#2/2))))};
    \end{axis}
  \end{tikzpicture}
}

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \sigmoidfixed{2.5}{235}{0.5}
    \caption{$r = 2.5$}
  \end{subfigure}
  \begin{subfigure}[b]{0.3\textwidth}
    \sigmoidfixed{3.5}{235}{0.5}
    \caption{$r = 3.5$}
  \end{subfigure}
  \begin{subfigure}[b]{0.3\textwidth}
    \sigmoidfixed{4.5}{235}{0.5}
    \caption{$r = 4.5$}
  \end{subfigure}
  \caption{Penalization functions for various ratios controlling steepness and
  shift}
  \label{fig:sigmoid-penalizations}
\end{figure}

As we want a good distribution, but still not penalize most recent items
linearly we choose a ratio of $3.5$ for our dataset, which creates the
distribution seen below. Tests were also carried out verifying that this was a
good selection.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{image/dist-sigmoid-fixed-recentness-3-5}
  \caption{Distribution of ratings using number of days since earliest event,
  a logistic penalization function and global min/max feature-values}
  \label{fig:dist-recentness-sigmoid}
\end{figure}

As discussed in the previous section, using number of days since most recent
event has many weaknesses, most notably the returning user - who if absent for
a longer time finds all items previously viewed or bought heavily penalized.
Instead we can use the ordering of items with a logistic penalization function
as well. Continuing with a ratio of $3.5$ we obtain the following distribution:

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{image/dist-sigmoid-fixed-count-3-5}
  \caption{Distribution using ordering of events, a logistic penalization
  function and global min/max feature-values}
  \label{fig:dist-count-sigmoid}
\end{figure}

\subsection{Linearly blending implicit ratings}

At this point we have found multiple ways of calculating the implicit ratings,
based on our implicit feedback. However, each method has its weknesses,
strengths and captures different feature-sets in our data. Thus the
distributions reflect a large difference in ratings. Selecting a feature such
as number of days since the event in question captures our implicit knowledge
about seasons and items having a short life-span. However, as pointed out
earlier given many events on the same day there are no way of differentiating
them - unless we consider the ordering of items, saying the most recent item
shall be higher rated than older events. However, exclusivly changing the
feature like this forces us to loose some of our implicit data about items
having a fixed lifespan. What we want to do is \textit{combine the two
features} in a procedure that often in recommender systems are coined
\textit{blending} or \textit{ensamble methods}. Combining them enables us to
create more robust ratings where weaknesses such as outliers or inconsistencies
in one method can be averaged out by the strengths of others. If two features
independently finds the same properties and ratings for some items and users,
then the result and our belief is strenghtened.

When linearly blending $M$ models $m_1 \dots m_M$, we choose $M$ factors $f_i$
all adding up to 1.0, representing the weight of model $m_{i}$ in the final
blend. Eeach model then have $k$ ratings on the triplet form \textit{(user,
product, rating)} and noted noted as $r_{ij}$ - the rating of item $j$ in model
$i$. 

Then when calculating the final rating for item $j$ we sum over all
models:

\begin{equation}
  r_j = \sum _{i=1}^{M} f_{i} * r_{ij}
\end{equation}

Given two models, we can observe the result of performing a blend between with
factors $f_1 = 0.7$ and $f_2 = 0.3$ and the two ratings $r_{11} = 5$ and
$m_{21} = 3$ for a given item, we can calculate the final rating as $(0.7
\times 5) + (0.3 \times 3) = 4.4$. The obvious weakness in this approach is the
need for manually setting weights for $M$ different factors. Optimally we would
like to run one blend, look at the result, compare it to previous results and
make adjustments to the weights based these. This is what is done in simple
blending schemes using Linear Regression or KNN, but many state-of-the-art
schemes exists as well such as Binned Linear Regression, Bagged Gradient
Boosted Decision Tree (BGBDT), Neural Networks and Kernel Ridge Regression
Blending \cite{jahrer2010combining} \cite{toscher2009bigchaos} which are based
on the same principles.

However, as discussed in Section~\ref{}, when creating ratings from implicit
feedback we lack a ground truth â that is we make several assumptions on which
implicit features contribute towards higher preference and thus higher ratings,
but with no real means of confirming the assumptions. A user buying an item as
a gift for a friend may not actually like the item and would not give a high
rating - and this, with a traditional collaborative filtering approach based on
explicit feedback would be accounted for, looking at the user pattern of the
user and labeling the purchase as an outlier. Without this ground truth however
we can not without injecting negative feedback, based on assumptions, make
classifications of outliers nor evaluate our implicit ratings in a reliable and
quantiative fashion. Without a good evaluation metric and grund truth there
does not exists a simple way of comparing different blends with eachothers
neither, hence making it difficult to find custom weights for each method.

Instead, we return to our introductionary text where we notice some factors
important to evaluating ratings: it needs to be evenly distributed, it should
have an average confirming our hypthesis and the features selected should
capture properties found in the domain both intutivly and quantitativly.  Then
for $M$ different models we assume they all contribute an equal amount to the
final results thus having the weights $f_i = 1/M$. By using this simple
linear blending we can combine our methods looking at recentness and ordering
using a linear penalization function
(Figure~\ref{fig:dist-recentness-linear-global} and~\ref{fig:dist-count-linear}
respectivly) with the ratings generated on the same features with a logistic
penalization function (Figure~\ref{fig:dist-recentness-sigmoid}
and~\ref{fig:dist-count-sigmoid}). This yields the following distribution of
ratings with the average $3.30$ and median at $3.63$, where the distributions
overlayed with the kernel density function, showing the trend of histogram:

\begin{figure}[H]
  \centering
  \label{dist-blend}
  \includegraphics[scale=0.5]{image/dist-blend}
  \caption{Distribution using blend of ordering and number of days since event,
  with logistic and linear penalization functions, overlayed with density
  function}
\end{figure}

Especially noticable in this distribution is that we've achieved a even
distribution without too many fluxuations. In addition there is a rounded peak
aroung the rating 4, which by looking at other public datasets such as in the
Netflix Prize~\cite{Netflix} or Million Song Dataset~\cite{Bertin-Mahieux-2011}
is a common peak found in explicit environments. Indeed, there is a small gap
where the scores between our two events \textit{click} and \textit{want} are
bordering, a result of our sigmoid functions having a ratio of $3.5$ which
yields a gradual slope - hence when we have x-values close to $M_u$ and $0$ we
approximate $1$ and $0$ respectivly, but we do not reach it exactly. This can
be seen on Figure~\ref{fig:sigmoid-penalizations}
